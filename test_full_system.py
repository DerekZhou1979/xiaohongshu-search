#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œæ•´ç³»ç»Ÿæµ‹è¯•è„šæœ¬
æµ‹è¯•ç²¾å‡†å®¹å™¨æå–åŠŸèƒ½æ˜¯å¦æ­£å¸¸é›†æˆåˆ°ä¸»ç³»ç»Ÿä¸­
"""

import os
import sys
import time
import json
import requests
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, PROJECT_ROOT)

def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    print("ğŸ”— æµ‹è¯•APIè¿æ¥...")
    try:
        response = requests.get("http://localhost:8080/", timeout=10)
        if response.status_code == 200:
            print("âœ… APIè¿æ¥æ­£å¸¸")
            return True
        else:
            print(f"âŒ APIè¿æ¥å¤±è´¥: HTTP {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ APIè¿æ¥å¤±è´¥: {e}")
        return False

def test_search_api():
    """æµ‹è¯•æœç´¢API"""
    print("\nğŸ” æµ‹è¯•æœç´¢API...")
    
    test_keywords = ["ç¾é£Ÿ", "è€åº™é»„é‡‘", "æ—¶å°š"]
    
    for keyword in test_keywords:
        print(f"\nğŸ” æµ‹è¯•å…³é”®è¯: {keyword}")
        try:
            url = f"http://localhost:8080/api/search?keyword={keyword}&max_results=5"
            response = requests.get(url, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                print(f"   ğŸ“Š è¿”å›ç»“æœ: {data.get('count', 0)} æ¡")
                print(f"   ğŸ“ çŠ¶æ€æ¶ˆæ¯: {data.get('message', 'N/A')}")
                
                if data.get('count', 0) > 0:
                    print(f"   âœ… æˆåŠŸæ‰¾åˆ° {data['count']} æ¡ç¬”è®°")
                    
                    # æ˜¾ç¤ºç¬¬ä¸€æ¡ç»“æœçš„è¯¦ç»†ä¿¡æ¯
                    first_note = data['notes'][0]
                    print(f"   ğŸ“ ç¤ºä¾‹ç¬”è®°:")
                    print(f"      ID: {first_note.get('note_id', 'N/A')}")
                    print(f"      æ ‡é¢˜: {first_note.get('title', 'N/A')[:30]}...")
                    print(f"      ä½œè€…: {first_note.get('author', 'N/A')}")
                    print(f"      å›¾ç‰‡æ•°: {len(first_note.get('images', []))}")
                    print(f"      æå–æ–¹æ³•: {first_note.get('method', 'N/A')}")
                    
                    return True
                else:
                    print(f"   âš ï¸  æœªæ‰¾åˆ°ç»“æœ")
                    
            else:
                print(f"   âŒ APIé”™è¯¯: HTTP {response.status_code}")
                
        except Exception as e:
            print(f"   âŒ è¯·æ±‚å¤±è´¥: {e}")
    
    return False

def test_precise_extraction_integration():
    """æµ‹è¯•ç²¾å‡†æå–åŠŸèƒ½æ˜¯å¦å·²é›†æˆ"""
    print("\nğŸ¯ æµ‹è¯•ç²¾å‡†æå–åŠŸèƒ½é›†æˆ...")
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„HTMLæ–‡ä»¶å¯ç”¨äºæµ‹è¯•
        cache_temp_dir = "cache/temp"
        if os.path.exists(cache_temp_dir):
            html_files = [f for f in os.listdir(cache_temp_dir) if f.endswith('.html')]
            if html_files:
                print(f"   ğŸ“ æ‰¾åˆ° {len(html_files)} ä¸ªç¼“å­˜HTMLæ–‡ä»¶")
                
                # è¿è¡Œæˆ‘ä»¬çš„ç²¾å‡†æå–è„šæœ¬
                import subprocess
                result = subprocess.run(['python', 'precise_extraction.py'], 
                                      capture_output=True, text=True)
                
                if result.returncode == 0:
                    print("   âœ… ç²¾å‡†æå–è„šæœ¬è¿è¡ŒæˆåŠŸ")
                    
                    # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ç»“æœæ–‡ä»¶
                    if os.path.exists('cache/precise_extracted_notes.json'):
                        with open('cache/precise_extracted_notes.json', 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        print(f"   ğŸ“Š ç²¾å‡†æå–ç»“æœ: {data.get('count', 0)} æ¡ç¬”è®°")
                        print(f"   âœ… ç²¾å‡†æå–åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
                        return True
                    else:
                        print("   âš ï¸  æœªæ‰¾åˆ°ç²¾å‡†æå–ç»“æœæ–‡ä»¶")
                else:
                    print(f"   âŒ ç²¾å‡†æå–è„šæœ¬å¤±è´¥: {result.stderr}")
            else:
                print("   âš ï¸  æœªæ‰¾åˆ°ç¼“å­˜HTMLæ–‡ä»¶")
        else:
            print("   âš ï¸  ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
            
        return False
        
    except Exception as e:
        print(f"   âŒ æµ‹è¯•ç²¾å‡†æå–åŠŸèƒ½å¤±è´¥: {e}")
        return False

def test_strategies_configuration():
    """æµ‹è¯•ç­–ç•¥é…ç½®"""
    print("\nâš™ï¸  æµ‹è¯•ç­–ç•¥é…ç½®...")
    
    try:
        # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„é…ç½®
        import os
        crawl_config = os.environ.get('CRAWL_CONFIG')
        
        if crawl_config:
            config = json.loads(crawl_config)
            print("   ğŸ“‹ å½“å‰é…ç½®:")
            print(f"      ç­–ç•¥1: {'âœ…' if config.get('enable_strategy_1') else 'âŒ'}")
            print(f"      ç­–ç•¥2: {'âœ…' if config.get('enable_strategy_2') else 'âŒ'}")
            print(f"      ç­–ç•¥3: {'âœ…' if config.get('enable_strategy_3') else 'âŒ'}")
            print(f"      ç­–ç•¥4: {'âœ…' if config.get('enable_strategy_4', True) else 'âŒ'}")
            print(f"      éªŒè¯ä¸¥æ ¼åº¦: {config.get('validation_strict_level', 'N/A')}")
            print(f"      åå°æå–: {'âœ…' if config.get('enable_backend_extraction') else 'âŒ'}")
            
            return True
        else:
            print("   âš ï¸  æœªæ‰¾åˆ°çˆ¬è™«é…ç½®")
            return False
            
    except Exception as e:
        print(f"   âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def generate_test_report():
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“‹ å®Œæ•´ç³»ç»Ÿæµ‹è¯•æŠ¥å‘Š")
    print("="*60)
    
    test_results = []
    
    # APIè¿æ¥æµ‹è¯•
    api_ok = test_api_connection()
    test_results.append(("APIè¿æ¥", api_ok))
    
    # ç­–ç•¥é…ç½®æµ‹è¯•
    config_ok = test_strategies_configuration()
    test_results.append(("ç­–ç•¥é…ç½®", config_ok))
    
    # ç²¾å‡†æå–é›†æˆæµ‹è¯•
    extraction_ok = test_precise_extraction_integration()
    test_results.append(("ç²¾å‡†æå–é›†æˆ", extraction_ok))
    
    # æœç´¢APIæµ‹è¯•
    search_ok = test_search_api()
    test_results.append(("æœç´¢APIåŠŸèƒ½", search_ok))
    
    # ç”Ÿæˆæ€»ç»“
    print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
    print(f"   æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    passed = sum(1 for _, result in test_results if result)
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        print("\nğŸ“Œ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("   1. è®¿é—® http://localhost:8080 ä½¿ç”¨Webç•Œé¢")
        print("   2. æˆ–ç›´æ¥è°ƒç”¨API: http://localhost:8080/api/search?keyword=å…³é”®è¯")
        print("   3. æŸ¥çœ‹ç”Ÿæˆçš„HTMLæŠ¥å‘Š: cache/precise_notes_report.html")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®")
        
        if not api_ok:
            print("   ğŸ’¡ å»ºè®®: æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦æ­£å¸¸å¯åŠ¨")
        if not search_ok:
            print("   ğŸ’¡ å»ºè®®: å¯èƒ½éœ€è¦åˆ·æ–°cookiesæˆ–ç­‰å¾…åˆå§‹åŒ–å®Œæˆ")
        if not extraction_ok:
            print("   ğŸ’¡ å»ºè®®: æ£€æŸ¥beautifulsoup4æ˜¯å¦å·²å®‰è£…")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å®Œæ•´ç³»ç»Ÿæµ‹è¯•å¼€å§‹")
    print("æµ‹è¯•å°çº¢ä¹¦æœç´¢å·¥å…·çš„ç²¾å‡†æå–åŠŸèƒ½é›†æˆæƒ…å†µ")
    print("="*60)
    
    try:
        generate_test_report()
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 